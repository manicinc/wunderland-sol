#!/usr/bin/env node
/**
 * Build BM25 postings and semantic embeddings for Frame Codex search.
 *
 * @remarks
 * - Consumes codex-index.json (generated by scripts/auto-index.js)
 * - Generates codex-search.json with:
 *   - BM25 postings (term -> [docId, termFrequency])
 *   - Document metadata (path, title, summary, docLength)
 *   - Packed Float32 embeddings (all-MiniLM-L6-v2, mean pooled, normalized)
 * - Embeddings are stored as base64 Float32Array to keep payload compact.
 * - This script is intended to run in CI after the auto-index step.
 */

import fs from 'fs'
import path from 'path'
import { pipeline } from '@huggingface/transformers'

const ROOT = process.cwd()
const INDEX_PATH = path.join(ROOT, 'codex-index.json')
const OUTPUT_PATH = path.join(ROOT, 'codex-search.json')

const STOP_WORDS = new Set([
  'the',
  'a',
  'an',
  'and',
  'or',
  'but',
  'in',
  'on',
  'at',
  'to',
  'for',
  'of',
  'with',
  'by',
  'from',
  'as',
  'is',
  'was',
  'are',
  'been',
  'be',
  'have',
  'has',
  'had',
  'do',
  'does',
  'did',
  'will',
  'would',
  'should',
  'could',
  'may',
  'might',
  'must',
  'can',
  'this',
  'that',
  'these',
  'those',
  'i',
  'you',
  'he',
  'she',
  'it',
  'we',
  'they',
  'what',
  'which',
  'who',
  'when',
  'where',
  'why',
  'how',
  'all',
  'each',
  'every',
  'both',
  'few',
  'more',
  'most',
  'other',
  'some',
  'such',
  'no',
  'nor',
  'not',
  'only',
  'own',
  'same',
  'so',
  'than',
  'too',
  'very',
  's',
  't',
  'just',
  'don',
  'now',
  'use',
  'using',
  'used',
])

const tokenize = (text = '') =>
  text
    .toLowerCase()
    .replace(/[^\w\s]/g, ' ')
    .split(/\s+/)
    .filter((term) => term.length > 2 && !STOP_WORDS.has(term))

const deriveWeave = (filePath = '') => {
  const segments = filePath.split('/')
  return segments.length > 1 ? segments[1] : ''
}

const deriveLoom = (filePath = '') => {
  const segments = filePath.split('/')
  if (segments.length <= 3) return ''
  // Remove leading 'weaves' and weave slug, drop filename
  return segments.slice(2, -1).join('/')
}

async function buildSearchIndex() {
  if (!fs.existsSync(INDEX_PATH)) {
    throw new Error(`Missing codex-index.json at ${INDEX_PATH}. Run "npm run index" first.`)
  }

  const rawIndex = fs.readFileSync(INDEX_PATH, 'utf8')
  const entries = JSON.parse(rawIndex)
  if (!Array.isArray(entries) || entries.length === 0) {
    throw new Error('codex-index.json is empty or malformed.')
  }

  console.log(`ğŸ“š Building search data for ${entries.length} strands...`)

  const bm25 = {
    totalDocs: entries.length,
    totalLength: 0,
    docs: [],
    vocabulary: new Map(),
  }

  const embedder = await pipeline('feature-extraction', 'Xenova/all-MiniLM-L6-v2')
  let embeddingSize = 0
  let embeddingArray = null

  for (let docId = 0; docId < entries.length; docId += 1) {
    const entry = entries[docId]
    const meta = entry.metadata || {}
    const title = meta.title || entry.name || entry.path
    const summary = meta.summary || ''
    const weave = deriveWeave(entry.path)
    const loom = deriveLoom(entry.path)
    const textSource = [title, summary, entry.content || ''].filter(Boolean).join('\n').slice(0, 8000)

    const tokens = tokenize(textSource)
    const docLength = tokens.length || 1
    bm25.totalLength += docLength

    bm25.docs.push({
      path: entry.path,
      title,
      summary,
      weave,
      loom,
      docLength,
    })

    const termFrequency = new Map()
    tokens.forEach((token) => {
      termFrequency.set(token, (termFrequency.get(token) || 0) + 1)
    })

    for (const [term, tf] of termFrequency.entries()) {
      if (!bm25.vocabulary.has(term)) {
        bm25.vocabulary.set(term, [])
      }
      bm25.vocabulary.get(term).push([docId, tf])
    }

    const embeddingInput = summary ? `${title}. ${summary}` : textSource || title
    const tensor = await embedder(embeddingInput || 'frame codex', {
      pooling: 'mean',
      normalize: true,
    })
    const vector = tensor.data

    if (!embeddingSize) {
      embeddingSize = vector.length
    }
    if (!embeddingArray) {
      embeddingArray = new Float32Array(entries.length * embeddingSize)
    }

    embeddingArray.set(vector, docId * embeddingSize)

    if (docId % 50 === 0) {
      console.log(`   â€¢ Processed ${docId + 1}/${entries.length} strands`)
    }
  }

  const avgDocLength = bm25.totalDocs > 0 ? bm25.totalLength / bm25.totalDocs : 0
  const vocabularyObject = Object.fromEntries(
    Array.from(bm25.vocabulary.entries()).sort(([a], [b]) => a.localeCompare(b)),
  )

  const slicedEmbeddings =
    embeddingSize > 0 && embeddingArray ? embeddingArray.subarray(0, bm25.totalDocs * embeddingSize) : new Float32Array()
  const embeddingsBase64 = Buffer.from(slicedEmbeddings.buffer).toString('base64')

  const searchIndex = {
    generatedAt: new Date().toISOString(),
    stats: {
      totalDocs: bm25.totalDocs,
      avgDocLength,
      vocabularySize: Object.keys(vocabularyObject).length,
    },
    docs: bm25.docs,
    vocabulary: vocabularyObject,
    embeddings: {
      size: embeddingSize,
      data: embeddingsBase64,
    },
  }

  fs.writeFileSync(OUTPUT_PATH, JSON.stringify(searchIndex))
  const fileSizeKb = (fs.statSync(OUTPUT_PATH).size / 1024).toFixed(1)
  console.log(`âœ… Wrote ${OUTPUT_PATH} (${fileSizeKb} KB, vocab ${searchIndex.stats.vocabularySize})`)
}

buildSearchIndex().catch((error) => {
  console.error('âŒ Failed to build search index:', error)
  process.exit(1)
})


