/**
 * @fileoverview Defines the robust and detailed structure for a single message
 * within a conversation in AgentOS. This structure is designed for complex
 * interactions including tool usage, rich content embedding, user feedback,
 * and comprehensive metadata for analytics and adaptive GMI behavior.
 * It aims for compatibility with common LLM API formats (e.g., OpenAI).
 *
 * @module backend/agentos/core/conversation/ConversationMessage
 * @see ../../cognitive_substrate/IGMI.ts for ToolCallRequest definition.
 * @see ../ai_utilities/IUtilityAI.ts for SentimentResult.
 */

import { ToolCallRequest as GMIToolCallRequest } from '../../cognitive_substrate/IGMI'; // Use the one from IGMI
import { SentimentResult } from '../ai_utilities/IUtilityAI';
import { uuidv4 } from '@framers/agentos/utils/uuid';

/**
 * Represents the role of the entity that produced the message.
 * Critical for LLM interpretation and system logic.
 */
export enum MessageRole {
  /** Instructions, context, or persona definitions provided by the system/developer. */
  SYSTEM = 'system',
  /** Input directly from the end-user. */
  USER = 'user',
  /** Responses generated by an AI agent or GMI. */
  ASSISTANT = 'assistant',
  /** Results or outputs from a tool execution, responding to an assistant's tool_call. */
  TOOL = 'tool',
  /**
   * A message representing a summarized block of older messages. Used internally
   * by ConversationContext to manage history length while preserving information.
   */
  SUMMARY = 'summary',
  /**
   * Represents an error message, distinct from a normal assistant response.
   * Could be for user display or internal logging.
   */
  ERROR = 'error',
  /**
   * Represents an agent's internal "thought" or intermediate reasoning step.
   * Typically not shown to the user but logged or used for self-correction.
   */
  THOUGHT = 'thought',
}

/**
 * Represents a request from an 'assistant' message to call one or more tools/functions.
 * This re-uses the `ToolCallRequest` from `IGMI.ts` for consistency.
 * The `arguments` field here is expected to be a pre-parsed object,
 * as the LLM's string arguments should be parsed before this stage.
 */
export type ConversationToolCallRequest = GMIToolCallRequest; // Alias for clarity if needed

/**
 * Optional, extensive metadata associated with a message, allowing for rich analytics,
 * feedback processing, and adaptive system behavior.
 */
export interface MessageMetadata {
  /** If message content was modified (e.g., truncated, summarized), provides details. */
  modificationInfo?: {
    strategy: 'truncated' | 'summarized' | 'filtered' | 'anonymized';
    originalTokenCount?: number;
    finalTokenCount?: number;
    originalLengthChars?: number;
    originalMessageCount?: number; // If this message is a summary of multiple messages
    reason?: string;
  };
  /** Calculated token count of the `content` field, if available. */
  tokenCount?: number;
  /** Detected language code of message content (e.g., 'en', 'es', 'fr-CA'). */
  language?: string;
  /** Confidence score for detected language (0-1). */
  languageConfidence?: number;
  /** Sentiment analysis result. */
  sentiment?: SentimentResult;
  /** Source or channel of message (e.g., 'direct_text_input', 'stt_whisper', 'tool_web_search'). */
  source?: string;
  /** User feedback on the message. */
  userFeedback?: {
    rating?: 'positive' | 'negative' | 'neutral' | number; // e.g., 1-5 scale
    feedbackTextId?: string; // Link to more detailed textual feedback
    tags?: string[];
    correctedContent?: string; // User-provided correction
  };
  /** Custom tags or keywords for categorization or filtering. */
  customTags?: string[];
  /**
   * Controls visibility or processing.
   * 'user': Visible to end-user.
   * 'developer_log': For debugging, not typically shown to users.
   * 'system_internal': For AgentOS internal processing.
   * 'gmi_memory': For GMI's internal memory or thought process.
   */
  visibility?: 'user' | 'developer_log' | 'system_internal' | 'gmi_memory';
  /** If this message is a response to a specific previous message, its ID. */
  inReplyToMessageId?: string;
  /** ID of the GMI Persona that generated/processed this message. */
  agentPersonaId?: string;
  /** GMI's mood when message was generated (if applicable). */
  agentMood?: string;
  /** Confidence score of AI generating this message (0-1). */
  generationConfidence?: number;
  /** Should this message be considered for long-term memory (RAG) ingestion? */
  storeInLongTermMemory?: boolean;
  /** Alternative content representations (e.g., SSML for speech, direct audio URL). */
  alternativeRepresentations?: {
    ssml?: string;
    audioUrl?: string;
    displayText?: string; // If `content` is complex (e.g. structured data)
  };
  /** For `SUMMARY` role, IDs of messages that were summarized. */
  summarizedMessageIds?: string[];
  /** For `ERROR` role, specific error code. */
  errorCode?: string;
  /** For `TOOL` role, duration of the tool execution in milliseconds. */
  toolExecutionDurationMs?: number;
  /** Any other custom key-value pairs for extensibility. */
  [key: string]: any;
}

/**
 * @interface ConversationMessage
 * @description Represents a single, comprehensive message within a conversation.
 * This structure is designed for rich interactions, compatibility with LLM APIs,
 * and detailed state management.
 */
export interface ConversationMessage {
  /**
   * Unique, immutable identifier for this message (e.g., UUID v4).
   * Essential for tracking, referencing, and storage.
   * @readonly
   */
  readonly id: string;

  /** The role of the message sender. */
  role: MessageRole;

  /**
   * The primary content of the message.
   * - For `USER`, `SYSTEM`, `SUMMARY`, `ERROR`, `THOUGHT`: string.
   * - Can be `null` for `ASSISTANT` messages that *only* contain `tool_calls`.
   * - For `TOOL` (tool result): Typically a string (e.g., stringified JSON of the output).
   * - For `USER` with multimodal input, this might be an array of content parts,
   * e.g., `[{type: 'text', text: '...'}, {type: 'image_url', image_url: '...'}]`.
   * The type `string | null | Array<Record<string, any>>` allows flexibility.
   */
  content: string | null | Array<Record<string, any>>;

  /**
   * Timestamp of when the message was created or logged (Unix epoch in milliseconds).
   * @readonly
   */
  readonly timestamp: number;

  /**
   * Optional. Name of the author or entity.
   * - For `role: TOOL`, this **must** be the `name` of the tool that produced the content (matching `ToolCallRequest.name`).
   * - For `role: ASSISTANT`, could be `agentPersonaId`.
   * - For `role: USER`, could be `userId`.
   */
  name?: string;

  /**
   * Optional. For `role: ASSISTANT` messages.
   * An array of tool calls requested by the assistant. Matches OpenAI's structure.
   * Arguments within `ConversationToolCallRequest.arguments` are expected to be objects (pre-parsed).
   */
  tool_calls?: ConversationToolCallRequest[];

  /**
   * Optional. For `role: TOOL` messages.
   * The unique `id` from the `ConversationToolCallRequest` this tool message responds to.
   * **Required if role is TOOL.**
   */
  tool_call_id?: string;

  /**
   * Optional. For `SUMMARY` role: number of original messages condensed.
   */
  originalMessagesSummarizedCount?: number;

  /**
   * Optional. Rich metadata object for additional information.
   */
  metadata?: MessageMetadata;
}

/**
 * Utility function to create a new ConversationMessage with defaults.
 * @param {MessageRole} role - The role of the message.
 * @param {string | null | Array<Record<string, any>>} content - The message content.
 * @param {Partial<Omit<ConversationMessage, 'id' | 'timestamp' | 'role' | 'content'>>} [options] - Optional additional properties.
 * @returns {ConversationMessage} The created conversation message.
 */
type ConversationMessageOptions = Partial<Omit<ConversationMessage, 'role' | 'content'>>;

export function createConversationMessage(
  role: MessageRole,
  content: ConversationMessage['content'],
  options?: ConversationMessageOptions,
): ConversationMessage {
  const { id, timestamp, ...restOptions } = options ?? {};
  const message: ConversationMessage = {
    id: id ?? `msg_${uuidv4()}`,
    timestamp: typeof timestamp === 'number' ? timestamp : Date.now(),
    role,
    content,
    ...restOptions,
  };

    // Ensure content consistency based on role, especially for OpenAI compatibility
    if (role === MessageRole.ASSISTANT && message.tool_calls && message.tool_calls.length > 0 && content === undefined) {
        message.content = null; // OpenAI allows null content for assistant if tool_calls are present
    } else if (role === MessageRole.TOOL && !message.tool_call_id) {
        console.warn("Creating TOOL message without 'tool_call_id'. This is required by most LLMs.");
    } else if ((role === MessageRole.USER || role === MessageRole.SYSTEM) && content === null) {
        // User and System messages typically require string content.
        // Allowing null here if explicitly passed but might be an issue for some LLMs.
        // Consider defaulting to "" if null and role isn't ASSISTANT (with tool_calls).
    }

    return message;
}
