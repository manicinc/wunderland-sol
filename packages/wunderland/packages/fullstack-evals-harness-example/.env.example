# Eval Harness Environment Configuration
# Copy to .env and fill in your API keys. Both backend and frontend read from this single file.

# ===================
# LLM Provider Keys
# ===================

# OpenAI - https://platform.openai.com/api-keys
# Used for: LLM graders, candidate runners, promptfoo assertions
OPENAI_API_KEY=

# Anthropic - https://console.anthropic.com/
# Used for: Claude models as graders or candidates
ANTHROPIC_API_KEY=

# Ollama - https://ollama.ai/
# Used for: Local LLM inference (no API key needed, just the base URL)
OLLAMA_BASE_URL=http://localhost:11434

# ===================
# Default LLM Settings
# ===================
# These can also be configured in the Settings UI

# Provider: openai, anthropic, or ollama
LLM_PROVIDER=openai

# Model name examples:
# OpenAI: gpt-4o, gpt-4.1, gpt-4.1-mini, o3, o3-mini
# Anthropic: claude-opus-4-5-20251101, claude-sonnet-4-5-20250929, claude-haiku-4-5-20251001
# Ollama: llama3, mistral, codellama
LLM_MODEL=gpt-4.1

# Optional (legacy / alternative): some code paths also read OLLAMA_MODEL
# OLLAMA_MODEL=dolphin-llama3:8b

# Temperature (0.0 - 2.0)
LLM_TEMPERATURE=0.7

# Max tokens for responses
LLM_MAX_TOKENS=1024

# ===================
# Database
# ===================

# SQLite database path (relative to backend/)
DATABASE_PATH=./data/evals.sqlite

# ===================
# Server Configuration
# ===================

# Backend port (default: 3021)
PORT=3021

# Frontend port (default: 3020, set in package.json)
# FRONTEND_PORT=3020
